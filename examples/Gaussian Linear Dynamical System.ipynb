{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Linear Dynamical System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate local environment, see `Project.toml`\n",
    "import Pkg; Pkg.activate(\".\"); Pkg.instantiate();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example the goal is to estimate hidden states of a Linear Dynamical process where all hidden states are Gaussians. A simple multivariate Linear Gaussian State Space Model can be described with the following equations:\n",
    "\n",
    "$$\\begin{aligned}\n",
    " p(x_i|x_{i - 1}) & = \\mathcal{N}(x_i|A * x_{i - 1}, \\mathcal{P}),\\\\\n",
    " p(y_i|x_i) & = \\mathcal{N}(y_i|B * x_i, \\mathcal{Q}),\n",
    "\\end{aligned}$$\n",
    "\n",
    "where $x_i$ are hidden states, $y_i$ are noisy observations, $A$, $B$ are state transition and observational matrices, $\\mathcal{P}$ and $\\mathcal{Q}$ are state transition noise and observation noise covariance matrices. For a more rigorous introduction to Linear Gaussian Dynamical systems we refer to [Simo Sarkka, Bayesian Filtering and Smoothing](https://users.aalto.fi/~ssarkka/pub/cup_book_online_20131111.pdf) book.\n",
    "\n",
    "To model this process in `RxInfer`, first, we start with importing all needed packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using RxInfer, BenchmarkTools, Random, LinearAlgebra, Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step, is to generate some synthetic data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function generate_data(rng, A, B, Q, P)\n",
    "    x_prev = [ 10.0, -10.0 ]\n",
    "\n",
    "    x = Vector{Vector{Float64}}(undef, n)\n",
    "    y = Vector{Vector{Float64}}(undef, n)\n",
    "\n",
    "    for i in 1:n\n",
    "        x[i] = rand(rng, MvNormal(A * x_prev, Q))\n",
    "        y[i] = rand(rng, MvNormal(B * x[i], P))\n",
    "        x_prev = x[i]\n",
    "    end\n",
    "    \n",
    "    return x, y\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed for reproducibility\n",
    "seed = 1234\n",
    "\n",
    "rng = MersenneTwister(1234)\n",
    "\n",
    "# We will model 2-dimensional observations with rotation matrix `A`\n",
    "# To avoid clutter we also assume that matrices `A`, `B`, `P` and `Q`\n",
    "# are known and fixed for all time-steps\n",
    "θ = π / 35\n",
    "A = [ cos(θ) -sin(θ); sin(θ) cos(θ) ]\n",
    "B = diageye(2)\n",
    "Q = diageye(2)\n",
    "P = 25.0 .* diageye(2)\n",
    "\n",
    "# Number of observations\n",
    "n = 300;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = generate_data(rng, A, B, Q, P);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot our synthetic dataset. Lines represent our hidden states we want to estimate using noisy observations, which are represented as dots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px = plot()\n",
    "\n",
    "px = plot!(px, getindex.(x, 1), label = \"Hidden Signal (dim-1)\", color = :orange)\n",
    "px = scatter!(px, getindex.(y, 1), label = false, markersize = 2, color = :orange)\n",
    "px = plot!(px, getindex.(x, 2), label = \"Hidden Signal (dim-2)\", color = :green)\n",
    "px = scatter!(px, getindex.(y, 2), label = false, markersize = 2, color = :green)\n",
    "\n",
    "plot(px)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a model we use `GraphPPL` package and `@model` macro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@model function rotate_ssm(n, x0, A, B, Q, P)\n",
    "    \n",
    "    # We create constvar references for better efficiency\n",
    "    cA = constvar(A)\n",
    "    cB = constvar(B)\n",
    "    cQ = constvar(Q)\n",
    "    cP = constvar(P)\n",
    "    \n",
    "    # `x` is a sequence of hidden states\n",
    "    x = randomvar(n)\n",
    "    # `y` is a sequence of \"clamped\" observations\n",
    "    y = datavar(Vector{Float64}, n)\n",
    "    \n",
    "    x_prior ~ MvNormalMeanCovariance(mean(x0), cov(x0))\n",
    "    x_prev = x_prior\n",
    "    \n",
    "    for i in 1:n\n",
    "        x[i] ~ MvNormalMeanCovariance(cA * x_prev, cQ)\n",
    "        y[i] ~ MvNormalMeanCovariance(cB * x[i], cP)\n",
    "        x_prev = x[i]\n",
    "    end\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run inference we also specify prior for out first hidden state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = MvNormalMeanCovariance(zeros(2), 100.0 * diageye(2));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For large number of observations you need to use `limit_stack_depth = 100` option during model creation, e.g. \n",
    "# inference(..., options = (limit_stack_depth = 500, ))`\n",
    "result = inference(\n",
    "    model = rotate_ssm(length(y), x0, A, B, Q, P), \n",
    "    data = (y = y,),\n",
    "    free_energy = true\n",
    ");\n",
    "\n",
    "xmarginals = result.posteriors[:x]\n",
    "bfe        = result.free_energy;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px = plot()\n",
    "\n",
    "px = plot!(px, getindex.(x, 1), label = \"Hidden Signal (dim-1)\", color = :orange)\n",
    "px = plot!(px, getindex.(x, 2), label = \"Hidden Signal (dim-2)\", color = :green)\n",
    "\n",
    "px = plot!(px, getindex.(mean.(xmarginals), 1), ribbon = getindex.(var.(xmarginals), 1) .|> sqrt, fillalpha = 0.5, label = \"Estimated Signal (dim-1)\", color = :teal)\n",
    "px = plot!(px, getindex.(mean.(xmarginals), 2), ribbon = getindex.(var.(xmarginals), 2) .|> sqrt, fillalpha = 0.5, label = \"Estimated Signal (dim-1)\", color = :violet)\n",
    "\n",
    "plot(px)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from our plot, estimated signal resembles closely to the real hidden states with small variance. We maybe also interested in the value for minus log evidence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bfe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may be also interested in performance of our resulting Belief Propagation algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: /Users/bvdmitri/.julia/dev/ReactiveMP.jl/src/constraints/specifications is not an existing directory, Revise is not watching\n",
      "└ @ Revise /Users/bvdmitri/.julia/packages/Revise/do2nH/src/packagedef.jl:570\n"
     ]
    }
   ],
   "source": [
    "@benchmark inference(\n",
    "    model = rotate_ssm(length($y), $x0, $A, $B, $Q, $P), \n",
    "    data = (y = $y,)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.8.0",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
