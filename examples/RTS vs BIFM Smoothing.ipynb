{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RTS vs BIFM Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate local environment, see `Project.toml`\n",
    "import Pkg; Pkg.activate(\".\"); Pkg.instantiate(); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "___Credits to Martin de Quincey___\n",
    "\n",
    "This notebook performs Kalman smoothing on a factor graph using message passing, based on the BIFM Kalman smoother. This notebook is based on:\n",
    "\n",
    "1. F. Wadehn, “State Space Methods with Applications in Biomedical Signal Processing,” ETH Zurich, 2019. Accessed: Jun. 16, 2021. [Online]. Available: https://www.research-collection.ethz.ch/handle/20.500.11850/344762\n",
    "2. H. Loeliger, L. Bruderer, H. Malmberg, F. Wadehn, and N. Zalmai, “On sparsity by NUV-EM, Gaussian message passing, and Kalman smoothing,” in 2016 Information Theory and Applications Workshop (ITA), Jan. 2016, pp. 1–10. doi: 10.1109/ITA.2016.7888168.\n",
    "\n",
    "We perform Kalman smoothing in the linear state space model, represented by\n",
    "$$Z_{k+1} = A Z_k + B U_k$$\n",
    "$$Y_k = C Z_k + W_k$$\n",
    "with observations $Y_k$, latent states $Z_k$ and inputs $U_k$. $W_k$ is the observation noise. $A \\in \\mathrm{R}^{n \\times n}$, $B \\in \\mathrm{R}^{n \\times m}$ and $C \\in \\mathrm{R}^{d \\times n}$ are the transition matrices in the model. Here $n$, $m$ and $d$ denote the dimensionality of the latent, input and output dimension, respectively.\n",
    "\n",
    "The corresponding probabilistic model can be represented as \n",
    "$$\n",
    "    \\begin{split}\n",
    "        p(y,\\ z,\\ u)\n",
    "        &= p(z_0) \\prod_{k=1}^N p(y_k \\mid z_k)\\ p(z_k\\mid z_{k-1},\\ u_{k-1})\\ p(u_{k-1}) \\\\\n",
    "        &= \\mathcal{N}(z_0 \\mid \\mu_{z_0}, \\Sigma_{z_0}) \\left( \\prod_{k=1}^N \\mathcal{N}(y_k \\mid C z_k,\\ \\Sigma_W)\\ \\delta(z_k - (Az_{k-1} + Bu_{k-1})) \\mathcal{N}(u_{k-1} \\mid \\mu_{i_{k-1}},\\ \\Sigma_{u_{k-1}}) \\right)\n",
    "    \\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using RxInfer, Random, LinearAlgebra, BenchmarkTools, PyPlot, ProgressMeter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function generate_parameters(dim_out::Int64, dim_in::Int64, dim_lat::Int64; seed::Int64 = 123)\n",
    "    \n",
    "    # define noise levels\n",
    "    input_noise  = 500.0\n",
    "    output_noise = 50.0\n",
    "\n",
    "    # create random generator for reproducibility\n",
    "    rng = MersenneTwister(seed)\n",
    "\n",
    "    # generate matrices, input statistics and noise matrices\n",
    "    A      = diagm(0.8 .* ones(dim_lat) .+ 0.2 * rand(rng, dim_lat))                                            # size (dim_lat x dim_lat)\n",
    "    B      = rand(dim_lat, dim_in)                                                                              # size (dim_lat x dim_in)\n",
    "    C      = rand(dim_out, dim_lat)                                                                             # size (dim_out x dim_lat)\n",
    "    μu     = rand(dim_in) .* collect(1:dim_in)                                                                  # size (dim_in x 1)\n",
    "    Σu     = input_noise  .* collect(Hermitian(randn(rng, dim_in, dim_in) + diagm(10 .+ 10*rand(dim_in))))      # size (dim_in x dim_in)\n",
    "    Σy     = output_noise .* collect(Hermitian(randn(rng, dim_out, dim_out) + diagm(10 .+ 10*rand(dim_out))))   # size (dim_out x dim_out)\n",
    "    Wu     = cholinv(Σu)\n",
    "    Wy     = cholinv(Σy)\n",
    "    \n",
    "    # return parameters\n",
    "    return A, B, C, μu, Σu, Σy, Wu, Wy\n",
    "\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function generate_data(nr_samples::Int64, A::Array{Float64,2}, B::Array{Float64,2}, C::Array{Float64,2}, μu::Array{Float64,1}, Σu::Array{Float64,2}, Σy::Array{Float64,2}; seed::Int64 = 123)\n",
    "        \n",
    "    # create random data generator\n",
    "    rng = MersenneTwister(seed)\n",
    "    \n",
    "    # preallocate space for variables\n",
    "    z = Vector{Vector{Float64}}(undef, nr_samples)\n",
    "    y = Vector{Vector{Float64}}(undef, nr_samples)\n",
    "    u = rand(rng, MvNormal(μu, Σu), nr_samples)'\n",
    "    \n",
    "    # set initial value of latent states\n",
    "    z_prev = zeros(size(A,1))\n",
    "    \n",
    "    # generate data\n",
    "    for i in 1:nr_samples\n",
    "\n",
    "        # generate new latent state\n",
    "        z[i] = A * z_prev + B * u[i,:]\n",
    "\n",
    "        # generate new observation\n",
    "        y[i] = C * z[i] + rand(rng, MvNormal(zeros(dim_out), Σy))\n",
    "        \n",
    "        # generate new observation\n",
    "        z_prev .= z[i]\n",
    "        \n",
    "    end\n",
    "    \n",
    "    # return generated data\n",
    "    return z, y, u\n",
    "    \n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify settings\n",
    "nr_samples = 200\n",
    "dim_out = 3\n",
    "dim_in = 3\n",
    "dim_lat = 25\n",
    "\n",
    "# generate parameters\n",
    "A, B, C, μu, Σu, Σy, Wu, Wy = generate_parameters(dim_out, dim_in, dim_lat);\n",
    "            \n",
    "# generate data\n",
    "data_z, data_y, data_u = generate_data(nr_samples, A, B, C, μu, Σu, Σy);\n",
    "\n",
    "# visualise data\n",
    "plt.plot(data_y)\n",
    "plt.grid()\n",
    "plt.xlabel(\"sample\")\n",
    "plt.ylabel(\"observations\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@model function RTS_smoother(nr_samples::Int64, A::Array{Float64,2}, B::Array{Float64,2}, C::Array{Float64,2}, μu::Array{Float64,1}, Wu::Array{Float64,2}, Wy::Array{Float64,2})\n",
    "    \n",
    "    # fetch dimensionality\n",
    "    dim_lat = size(A, 1)\n",
    "    dim_out = size(C, 1)\n",
    "    \n",
    "    # initialize variables\n",
    "    z = randomvar(nr_samples)                 # hidden states (random variable)\n",
    "    u = randomvar(nr_samples)                 # inputs (random variable)\n",
    "    y = datavar(Vector{Float64}, nr_samples)  # outputs (observed variables)\n",
    "    \n",
    "    # set initial hidden state\n",
    "    z_prior ~ MvNormalMeanPrecision(zeros(dim_lat), 1e-5*diagm(ones(dim_lat)))\n",
    "    \n",
    "    # update last/previous hidden state\n",
    "    z_prev = z_prior\n",
    "\n",
    "    # loop through observations\n",
    "    for i in 1:nr_samples\n",
    "\n",
    "        # specify input as random variable\n",
    "        u[i] ~ MvNormalMeanPrecision(μu, Wu)\n",
    "        \n",
    "        # specify updated hidden state\n",
    "        z[i] ~ A * z_prev + B * u[i]\n",
    "        \n",
    "        # specify observation\n",
    "        y[i] ~ MvNormalMeanPrecision(C * z[i], Wy)\n",
    "        \n",
    "        # update last/previous hidden state\n",
    "        z_prev = z[i]\n",
    "\n",
    "    end\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@model function BIFM_smoother(nr_samples::Int64, A::Array{Float64,2}, B::Array{Float64,2}, C::Array{Float64,2}, μu::Array{Float64,1}, Wu::Array{Float64,2}, Wy::Array{Float64,2})\n",
    "\n",
    "    # fetch dimensionality\n",
    "    dim_lat = size(A, 1)\n",
    "    \n",
    "    # initialize variables\n",
    "    z  = randomvar(nr_samples)                  # latent states\n",
    "    yt = randomvar(nr_samples)                  # latent observations\n",
    "    y  = datavar(Vector{Float64}, nr_samples)   # actual observations\n",
    "    u  = randomvar(nr_samples)                  # inputs\n",
    "    \n",
    "    # set priors\n",
    "    z_prior ~ MvNormalMeanPrecision(zeros(dim_lat), 1e-5*diagm(ones(dim_lat)))\n",
    "    z_tmp   ~ BIFMHelper(z_prior) where { q = MeanField() }\n",
    "    \n",
    "    # update last/previous hidden state\n",
    "    z_prev = z_tmp\n",
    "    \n",
    "    # loop through observations\n",
    "    for i in 1:nr_samples\n",
    "\n",
    "        # specify input as random variable\n",
    "        u[i]   ~ MvNormalMeanPrecision(μu, Wu)\n",
    "\n",
    "        # specify observation\n",
    "        yt[i]  ~ BIFM(u[i], z_prev, z[i]) where { meta = BIFMMeta(A, B, C) }\n",
    "        y[i]   ~ MvNormalMeanPrecision(yt[i], Wy)\n",
    "        \n",
    "        # update last/previous hidden state\n",
    "        z_prev = z[i]\n",
    "\n",
    "    end\n",
    "    \n",
    "    # set final value\n",
    "    z[nr_samples] ~ MvNormalMeanPrecision(zeros(dim_lat), zeros(dim_lat, dim_lat))\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function inference_RTS(data_y, A, B, C, μu, Wu, Wy)\n",
    "    result = inference(\n",
    "        model      = RTS_smoother(length(data_y), A, B, C, μu, Wu, Wy),\n",
    "        data       = (y = data_y, ),\n",
    "        returnvars = (z = KeepLast(), u = KeepLast())\n",
    "    )\n",
    "    qs = result.posteriors\n",
    "    return (qs[:z], qs[:u])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function inference_BIFM(data_y, A, B, C, μu, Wu, Wy)\n",
    "    result = inference(\n",
    "        model      = BIFM_smoother(length(data_y), A, B, C, μu, Wu, Wy),\n",
    "        data       = (y = data_y, ),\n",
    "        returnvars = (z = KeepLast(), u = KeepLast())\n",
    "    )\n",
    "    qs = result.posteriors\n",
    "    return (qs[:z], qs[:u])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments for 200 observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_RTS, u_RTS = inference_RTS(data_y, A, B, C, μu, Wu, Wy)\n",
    "z_BIFM, u_BIFM = inference_BIFM(data_y, A, B, C, μu, Wu, Wy);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, figsize=(15,5))\n",
    "ax[1].plot(mean.(z_RTS), c=\"orange\")\n",
    "ax[1].scatter(repeat(0:nr_samples-1, 1, dim_lat)', hcat(data_z...), c=\"blue\", s=10, alpha=0.1)\n",
    "ax[2].plot(mean.(z_BIFM), c=\"orange\")\n",
    "ax[2].scatter(repeat(0:nr_samples-1, 1, dim_lat)', hcat(data_z...), c=\"blue\", s=10, alpha=0.1)\n",
    "ax[1].grid(), ax[2].grid()\n",
    "ax[1].set_xlabel(\"sample\"), ax[2].set_xlabel(\"sample\")\n",
    "ax[1].set_ylabel(\"latent state\"), ax[2].set_ylabel(\"latent state\")\n",
    "ax[1].set_xlim(0, nr_samples-1), ax[2].set_xlim(0, nr_samples-1)\n",
    "ax[1].set_title(\"RTS smoother\"), ax[2].set_title(\"BIFM smoother\")\n",
    "fig.suptitle(\"Latent state estimation\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, figsize=(15,5))\n",
    "ax[1].plot(mean.(u_RTS), c=\"orange\")\n",
    "ax[1].scatter(repeat(0:nr_samples-1, 1, dim_in)', hcat(data_u...), c=\"blue\", s=10, alpha=0.1)\n",
    "ax[2].plot(mean.(u_BIFM), c=\"orange\")\n",
    "ax[2].scatter(repeat(0:nr_samples-1, 1, dim_in)', hcat(data_u...), c=\"blue\", s=10, alpha=0.1)\n",
    "ax[1].grid(), ax[2].grid()\n",
    "ax[1].set_xlabel(\"sample\"), ax[2].set_xlabel(\"sample\")\n",
    "ax[1].set_ylabel(\"input\"), ax[2].set_ylabel(\"input\")\n",
    "ax[1].set_xlim(0, nr_samples-1), ax[2].set_xlim(0, nr_samples-1)\n",
    "ax[1].set_title(\"RTS smoother\"), ax[2].set_title(\"BIFM smoother\")\n",
    "fig.suptitle(\"Input estimation\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, figsize=(15,5))\n",
    "ax[1].plot(mean.(data_y), c=\"orange\")\n",
    "ax[1].scatter(repeat(0:nr_samples-1, 1, dim_out)', hcat(data_y...), c=\"blue\", s=10, alpha=0.1)\n",
    "ax[2].plot(mean.(data_y), c=\"orange\")\n",
    "ax[2].scatter(repeat(0:nr_samples-1, 1, dim_out)', hcat(data_y...), c=\"blue\", s=10, alpha=0.1)\n",
    "ax[1].grid(), ax[2].grid()\n",
    "ax[1].set_xlabel(\"sample\"), ax[2].set_xlabel(\"sample\")\n",
    "ax[1].set_ylabel(\"output state\"), ax[2].set_ylabel(\"output state\")\n",
    "ax[1].set_xlim(0, nr_samples-1), ax[2].set_xlim(0, nr_samples-1)\n",
    "ax[1].set_title(\"RTS smoother\"), ax[2].set_title(\"BIFM smoother\")\n",
    "fig.suptitle(\"Output estimation\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This example runs in our documentation pipeline, benchmark executes approximatelly in 20 minutes so we bypass it in the documentation\n",
    "# For those who are interested in exact benchmark numbers clone this example and set `run_benchmark = true`\n",
    "run_benchmark = false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_benchmark\n",
    "    trials_range = 50\n",
    "    trials_n = 200\n",
    "    trials_RTS  = Array{BenchmarkTools.Trial, 1}(undef, trials_range)\n",
    "    trials_BIFM = Array{BenchmarkTools.Trial, 1}(undef, trials_range)\n",
    "\n",
    "\n",
    "    @showprogress for k = 1 : trials_range\n",
    "\n",
    "        # generate parameters\n",
    "        A, B, C, μu, Σu, Σy, Wu, Wy = generate_parameters(3, 3, k);\n",
    "                    \n",
    "        # generate data|\n",
    "        data_z, data_y, data_u = generate_data(trials_n, A, B, C, μu, Σu, Σy);\n",
    "\n",
    "        # run inference\n",
    "        trials_RTS[k] = @benchmark inference_RTS($data_y, $A, $B, $C, $μu, $Wu, $Wy)\n",
    "        trials_BIFM[k] = @benchmark inference_BIFM($data_y, $A, $B, $C, $μu, $Wu, $Wy)\n",
    "\n",
    "    end\n",
    "\n",
    "    m_RTS = [median(trials_RTS[k].times) for k=1:trials_range] ./ 1e9\n",
    "    q1_RTS = [quantile(trials_RTS[k].times, 0.25) for k=1:trials_range] ./ 1e9\n",
    "    q3_RTS = [quantile(trials_RTS[k].times, 0.75) for k=1:trials_range] ./ 1e9\n",
    "    m_BIFM = [median(trials_BIFM[k].times) for k=1:trials_range] ./ 1e9\n",
    "    q1_BIFM = [quantile(trials_BIFM[k].times, 0.25) for k=1:trials_range] ./ 1e9\n",
    "    q3_BIFM = [quantile(trials_BIFM[k].times, 0.75) for k=1:trials_range] ./ 1e9;\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(1:trials_range, m_RTS, color=\"blue\", label=\"mean (RTS)\")\n",
    "    plt.fill_between(1:trials_range, q1_RTS, q3_RTS, color=\"blue\", alpha=0.3, label=\"IQ-range (RTS)\")\n",
    "    plt.plot(1:trials_range, m_BIFM, color=\"orange\", label=\"mean (BIFM)\")\n",
    "    plt.fill_between(1:trials_range, q1_BIFM, q3_BIFM, color=\"orange\", alpha=0.3, label=\"IQ-range (BIFM)\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.grid()\n",
    "    plt.xlabel(\"latent state dimension\")\n",
    "    plt.ylabel(\"duration [sec]\")\n",
    "    plt.legend()\n",
    "    plt.xlim(1, trials_range)\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
